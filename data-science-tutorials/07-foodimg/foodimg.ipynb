{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: Food Image Recognition\n",
        "author: 'Dr. Roch Nianogo, Bowen Zhang, Dr. Hua Zhou'\n",
        "format:\n",
        "  html:\n",
        "    theme: cosmo\n",
        "    embed-resources: true\n",
        "    number-sections: true\n",
        "    toc: true\n",
        "    toc-depth: 4\n",
        "    toc-location: left\n",
        "    code-fold: false\n",
        "    link-external-icon: true\n",
        "    link-external-newwindow: true\n",
        "knitr:\n",
        "  opts_chunk:\n",
        "    cache: false\n",
        "    echo: true\n",
        "    fig.align: center\n",
        "    message: false\n",
        "comments:\n",
        "  hypothesis: true\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This tutorial is sparked by a conversation with Dr. May Wang years ago. Also see this [blog](https://www.labellerr.com/blog/food-recognition-and-classification-using-deep-learning/amp/). This note is not to be reproduced on Posit Cloud. It requires downloading the food image data from [Kaggle](https://www.kaggle.com/datasets/kmader/food41) and significant computing resource (memory, GPU) to run the code.\n",
        "\n",
        "![](Food-image.jpeg){fig-align=\"center\" width=\"75%\"}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "#| output: false\n",
        "\n",
        "library(imager)\n",
        "library(keras)\n",
        "library(tidyverse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Learning objectives\n",
        "\n",
        "Keywords: Convolution neural network (CNN), transfer learning.\n",
        "\n",
        "## Data ingestion\n",
        "\n",
        "We will use the [Food-101 dataset](https://www.vision.ee.ethz.ch/datasets_extra/food-101/), which contains 101 food categories, each with 1,000 images. The images are of varying sizes and aspect ratios. We will resize the images to 224x224 pixels, which is the input size required by the pre-trained model we will use.\n",
        "\n",
        "```{bash}\n",
        "ls food/images\n",
        "```\n",
        "\n",
        "Create a tibble of file paths and labels for all food images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "image_df <- list.dirs(\"food/images\", full.names = TRUE, recursive = FALSE) %>%\n",
        "  map_dfr(~tibble(filepath = list.files(.x, full.names = TRUE), label = basename(.x))) %>%\n",
        "  # mutate(filepath = str_c(getwd(), filepath, sep = \"/\")) %>%\n",
        "  mutate(label = factor(label)) %>%\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Show a few random sample images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "set.seed(2024)\n",
        "\n",
        "num_images <- 6\n",
        "# par(mar = c(1, 1, 1, 1), mfrow = c(2, 3))\n",
        "for (i in 1:num_images) {\n",
        "  img <- image_df |> slice_sample(n = 1)\n",
        "  plot(load.image(img[[\"filepath\"]]))\n",
        "  title(img[[\"label\"]])\n",
        "};"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "How many images per food category?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "image_df %>%\n",
        "  count(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To save trees, we will only use only 100 images per food category."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "image_df <- image_df %>%\n",
        "  group_by(label) %>%\n",
        "  slice_sample(n = 100) %>%\n",
        "  ungroup() %>%\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Sanity check:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "image_df %>% \n",
        "  count(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data preprocessing\n",
        "\n",
        "We split the data into 60% training, 20% validation, and 20% testing set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "set.seed(2024)\n",
        "\n",
        "spec <- c(train = .6, test = .2, validate = .2)\n",
        "\n",
        "g = sample(cut(\n",
        "  seq(nrow(image_df)), \n",
        "  nrow(image_df) * cumsum(c(0, spec)),\n",
        "  labels = names(spec)\n",
        "))\n",
        "\n",
        "image_split <- split(image_df, g)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "train_data <- image_split$train\n",
        "x_train <- array(dim = c(nrow(train_data), 224, 224, 3))\n",
        "for (i in 1:nrow(train_data)) {\n",
        "    img <- image_load(train_data$filepath[i], target_size = c(224, 224))\n",
        "    x_train[i, , ,] <- image_to_array(img)\n",
        "}\n",
        "x_train <- mobilenet_preprocess_input(x_train)\n",
        "# x_train <- resnet_v2_preprocess_input(x_train)\n",
        "# x_train <- imagenet_preprocess_input(x_train)\n",
        "dim(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Encode label as binary class matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y_train <- to_categorical(as.integer(factor(train_data$label)) - 1)\n",
        "dim(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "validate_data <- image_split$validate\n",
        "x_validate <- array(dim = c(nrow(validate_data), 224, 224, 3))\n",
        "for (i in 1:nrow(validate_data)) {\n",
        "    img <- image_load(validate_data$filepath[i], target_size = c(224, 224))\n",
        "    x_validate[i, , ,] <- image_to_array(img)\n",
        "}\n",
        "x_validate <- mobilenet_preprocess_input(x_validate)\n",
        "# x_validate <- resnet_v2_preprocess_input(x_validate)\n",
        "# x_validate <- imagenet_preprocess_input(x_validate)\n",
        "dim(x_validate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y_validate <- to_categorical(as.integer(factor(validate_data$label)) - 1)\n",
        "dim(y_validate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "test_data <- image_split$test\n",
        "x_test <- array(dim = c(nrow(test_data), 224, 224, 3))\n",
        "for (i in 1:nrow(test_data)) {\n",
        "    img <- image_load(test_data$filepath[i], target_size = c(224, 224))\n",
        "    x_test[i, , ,] <- image_to_array(img)\n",
        "}\n",
        "x_test <- mobilenet_preprocess_input(x_test)\n",
        "# x_test <- resnet_v2_preprocess_input(x_test)\n",
        "# x_test <- imagenet_preprocess_input(x_test)\n",
        "dim(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y_test <- to_categorical(as.integer(factor(test_data$label)) - 1)\n",
        "dim(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model\n",
        "\n",
        "Instead of building and training a CNN from scratch, we will use a pre-trained model, [MobileNet](https://keras.io/api/applications/mobilenet/), and fine-tune it to our food image dataset. MobileNet is a CNN model that has been pre-trained on the ImageNet dataset. We will use the pre-trained model to extract features from our food images and then train a new model on top of these features.\n",
        "\n",
        "For a list of available pre-trained models, see [Keras Applications](https://keras.io/api/applications/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pretrained_model <- application_mobilenet(\n",
        "# pretrained_model <- application_resnet50_v2(\n",
        "  weights = \"imagenet\",\n",
        "  include_top = FALSE,\n",
        "  input_shape = c(224, 224, 3),\n",
        "  pooling = \"avg\"\n",
        ")\n",
        "# Freeze the weights of the pre-trained model\n",
        "pretrained_model$trainable <- FALSE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Add additional dense layers on top of the pre-trained model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Dropout doesn't seem to help\n",
        "# One layter of 256 units slightly better than 2 layers of 128 units\n",
        "model <- keras_model_sequential()  %>%\n",
        "  pretrained_model %>%\n",
        "  layer_dense(units = 256, activation = \"relu\") %>%\n",
        "  # layer_dropout(rate = 0.5) %>%\n",
        "  # layer_dense(units = 128, activation = \"relu\") %>%\n",
        "  # layer_dropout(rate = 0.5) %>%\n",
        "  layer_dense(units = 101, activation = \"softmax\")\n",
        "\n",
        "summary(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training\n",
        "\n",
        "Compile the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Slower learning rate helps\n",
        "# No big difference between rmsprop and adam\n",
        "model %>%\n",
        "  compile(\n",
        "    loss = \"categorical_crossentropy\",\n",
        "    # optimizer = \"rmsprop\",\n",
        "    optimizer = optimizer_rmsprop(learning_rate = 0.00005),\n",
        "    # optimizer = optimizer_adam(learning_rate = 0.0001),\n",
        "    metrics = c(\"accuracy\")\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "history <- model %>%\n",
        "  fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    validation_data = list(x_validate, y_validate),\n",
        "    epochs = 50,\n",
        "    batch_size = 32,\n",
        "    shuffle = TRUE,\n",
        "    callbacks = list(\n",
        "      callback_early_stopping(\n",
        "        monitor = \"val_accuracy\",\n",
        "        patience = 3,\n",
        "        restore_best_weights = TRUE\n",
        "        )\n",
        "    )\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plot(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model %>% \n",
        "  evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate predictions on new data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "predictions <- model %>% \n",
        "  predict(x_test) %>%\n",
        "  k_argmax()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "ir43",
      "language": "R",
      "display_name": "R 4.3.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}