{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: Policy Evaluation by Double Machine Learning\n",
        "author: 'Dr. Roch Nianogo, Bowen Zhang, Dr. Hua Zhou'\n",
        "format:\n",
        "  html:\n",
        "    theme: cosmo\n",
        "    embed-resources: true\n",
        "    number-sections: true\n",
        "    toc: true\n",
        "    toc-depth: 4\n",
        "    toc-location: left\n",
        "    code-fold: false\n",
        "    link-external-icon: true\n",
        "    link-external-newwindow: true\n",
        "knitr:\n",
        "  opts_chunk:\n",
        "    cache: false\n",
        "    echo: true\n",
        "    fig.align: center\n",
        "    message: false\n",
        "comments:\n",
        "  hypothesis: true\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "#| output: false\n",
        "\n",
        "library(tidyverse)\n",
        "library(tidycensus)\n",
        "census_api_key(\"4cf445b70eabd0b297a45e7f62f52c27ba3b5cae\",\n",
        "               install = TRUE, overwrite = TRUE)\n",
        "Sys.setenv(\"CENSUS_KEY\" = \"4cf445b70eabd0b297a45e7f62f52c27ba3b5cae\")\n",
        "\n",
        "library(censusapi)\n",
        "library(data.table)\n",
        "library(DoubleML)\n",
        "library(gtsummary)\n",
        "library(mlr3)\n",
        "library(ranger)\n",
        "library(tidymodels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Roadmap\n",
        "\n",
        "::: {style=\"text-align: center;\"}\n",
        "![Data Science Diagram](../01-dsintro/data-science.png)\n",
        ":::\n",
        "\n",
        "## Causal inference\n",
        "\n",
        "-   You've done tremendous work carrying out an intervention program. You want to demonstrate to stakeholders (government, funding agencies, etc) that your program \"works.\"\n",
        "\n",
        "    -   You compared the average of [Food Security Rasch Scale Score in the past 30 days](https://www.ers.usda.gov/media/8282/short2012.pdf) (higher score indicates lower food security) among program participants versus those not participating our program. We found a significant difference in the averages üòÑ But people criticize your analysis as biased üôÅ What could go wrong?\n",
        "\n",
        "    -   In another try, you ran a multiple linear regression that included the program participation status and many socio-economical variables (race, age, income, region, ...), hoping to adjust for hidden confounding. Then you found that program participation does not significantly improve the food security Rasch score üôÅ\n",
        "\n",
        "    -   Causal inference methods can help more reliably estimate the \"treatment effect.\"\n",
        "\n",
        "-   Main approaches for causal inference:\n",
        "\n",
        "    -   **RCT** (randomized controlled trials): gold standard, but impractical in most Community-Based Participatory Research (**CBPR**) with multi-level interventions.\n",
        "\n",
        "    -   Observational studies under unconfoundedness: matching, regression estimators, inverse-propensity-score weighting.\n",
        "\n",
        "    -   Observational studies without unconfoundedness: instrumental variable, difference-in-differences (DiD), synthetic control, regression discontinuity designs.\n",
        "\n",
        "## Partially linear regression and interactive regression model\n",
        "\n",
        "### Partially linear regression (PLR)\n",
        "\n",
        "Partially linear regression (PLR) model introduced by Robinson (1988):\n",
        "\n",
        "::: {style=\"text-align: center;\"}\n",
        "<img src=\"./PartialLR.drawio.png\" alt=\"PLR\" width=\"300\"/>\n",
        ":::\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "Y &= D \\theta_0 + g_0(X) + U, &E[U | X, D] = 0, \\\\\n",
        "D &= m_0(X) + V, &E[V | X] = 0.\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "Here, $Y$ is the outcome variable, $D$ is the policy/treatment variable of interest, vector\n",
        "\n",
        "$$\n",
        "X = (X_1, \\ldots, X_p)\n",
        "$$\n",
        "\n",
        "consists of other control, and $U$ and $V$ are disturbances terms. The first equation is the main equation, and $\\theta_0$ is the main regression coefficient that we would like to infer. If $D$ is exogenous conditional on controls X, $\\theta_0$ has the interpretation of the treatment effect parameter or ‚Äòlift‚Äô parameter in business applications. The second equation keeps track of confounding, namely the dependence of the treatment variable on controls.\n",
        "\n",
        "The confounding factors $X$ affect the policy variable $D$ via the function $m_0(X)$ and the outcome variable via the function $g_0(X)$. These function does not need to be linear! We can take advantage of the great prediction performance of machine learning techniques to estimate these functions.\n",
        "\n",
        "Naive application of machine learning methods directly to two equations may have a very high bias.\n",
        "\n",
        "::: {style=\"text-align: center;\"}\n",
        "<img src=\"./bias.jpg\" alt=\"bias\" width=\"700\"/>\n",
        ":::\n",
        "\n",
        "Remarks:\n",
        "\n",
        "1.  The policy variable $D$ can be either binary or continuous (dosage).\n",
        "\n",
        "2.  The policy variable $D$ can be multi-dimensional (multi-level intervention: food pantry, mobile clinics, referral system, education classes, ads.).\n",
        "\n",
        "### Interactive regression model (IRM)\n",
        "\n",
        "We consider estimation of average treatment effects when treatment effects are fully heterogeneous, i.e., the response curves under control and treatment can be different nonparametric functions, and the treatment variable is binary, $D \\in \\{0,1\\}$. We consider vectors $(Y,D,X)$ such that\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "Y &= g_0(D,X) + U, &E[U | X, D] = 0, \\\\\n",
        "D &= m_0(X) + V, &E[V | X] = 0.\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "Since $D$ is not additively separable, this model is more general than the partially linear model for the case of binary $D$. A common target parameter of interest in this model is the average treatment effect (ATE).\n",
        "\n",
        "$$\n",
        "\\theta_0 = E[g_0(1,X) - g_0(0,X)].\n",
        "$$\n",
        "\n",
        "The confounding factors $X$ affect the policy variable via the propensity score $m_0(X)$ and the outcome variable via the function $g_0(X)$. Both of these functions are unknown and potentially complex, and we can employ ML methods to learn them.\n",
        "\n",
        "The general idea for identification of $Œ∏_0$ using the IRM is similar. Once we are able to account for all confounding variables $X$ in our analysis, we can consistently estimate the causal parameter $\\theta_0$. A difference to the PLR refers to assumptions on the functional form of the main regression equation. Whereas it is assumed that the effect of $D$ on $Y$ in the PLR model is additively separable, the IRM model comes with less restrictive assumptions.\n",
        "\n",
        "### Basic Idea behind Double Machine Learning for the PLR Model\n",
        "\n",
        "The basic idea behind double machine learning method is to use machine learning methods to estimate the nuisance functions $m_0(X)$ and $g_0(X)$ and then use these estimates to construct a doubly robust estimator of the target parameter $\\theta_0$. The doubly robust estimator is consistent if either the machine learning estimator of $m_0(X)$ or $g_0(X)$ is consistent.\n",
        "\n",
        "Reference: [Chernozhukov, V., Chetverikov, D., Demirer, M., Duflo, E., Hansen, C., Newey, W., and Robins, J. (2018). Double/debiased machine learning for treatment and structural parameters. The Econometrics Journal, 21(1), C1-C68.](https://onlinelibrary.wiley.com/doi/abs/10.1111/ectj.12097)\n",
        "\n",
        "#### Idea 1: Neyman orthogonal score\n",
        "\n",
        "The Neyman orthogonal score is orthogonal to the nuisance parameter in the sense that its expectation is zero. The Neyman orthogonal score is a key concept in the theory of efficient estimation of the target parameter in semiparametric models.\n",
        "\n",
        "The PLR model can be rewritten in the following residualized form:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "W &= V\\theta_0 + \\zeta, &E[\\zeta | X, D] = 0, \\\\\n",
        "W &= (Y - \\ell_0(X)), &\\ell_0(X) = E[Y | X], \\\\\n",
        "V &= (D - m_0(X)), &m_0(X) = E[D | X].\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "The variable $W$ and $V$ represent original variables after taking out or **partialling out** the effect of X. Given identification, double machine learning for a PLR proceeds as follows:\n",
        "\n",
        "1.  Estimate $\\ell_0$ and $m_0$ by sloving two problems of predicting $Y$ and $D$ using $X$, using any generic machine learning method, giving us estimated residuals $$\n",
        "    \\begin{aligned}\n",
        "    \\hat{W} &= Y - \\hat{\\ell}_0(X), \\\\\n",
        "    \\hat{V} &= D - \\hat{m}_0(X).\n",
        "    \\end{aligned}\n",
        "    $$\n",
        "\n",
        "    The residuals should be of a cross-validated form to avoid overfitting.\n",
        "\n",
        "2.  Estimate $\\theta_0$ by regressing the residuals $\\hat{W}$ on $\\hat{V}$. Use the conventional inference for this regression estimator, ignoring the estimation error in $\\hat{W}$ and $\\hat{V}$.\n",
        "\n",
        "#### Idea 2: Sample splitting\n",
        "\n",
        "The key idea behind sample splitting is to split the sample into two parts, one for estimating the nuisance functions and the other for estimating the causal parameter. This is also known as **cross-fitting**.\n",
        "\n",
        "## Example: causal effect of WIC on food security\n",
        "\n",
        "### Background\n",
        "\n",
        "The Special Supplemental Nutrition Program for Women, Infants, and Children ([WIC](https://www.fns.usda.gov/wic)) is a federally funded nutrition program that provides grants to States to support distribution of supplemental foods, health care referrals, and nutrition education to safeguard the health of low-income pregnant, breastfeeding, and non-breastfeeding postpartum women; for infants in low-income families; and for children younger than age 5 in low-income families and who are found to be at nutritional risk.\n",
        "\n",
        "In 2020, WIC served over 6.2 million participants per month at an average monthly cost for food (after rebates to WIC from manufacturers) of about \\$38 per person. Many household under low food security benefit from WIC. We are curious to know the causal effect of WIC on food security status.\n",
        "\n",
        "### Data preparation\n",
        "\n",
        "We use the 2020 Current Population Survey (CPS) Food Security Supplement (FSS) data to estimate the causal effect of WIC on food security status. We screen the eligible household (below 185 percent of the poverty threshold, with children under age 5 or women aged 15-45). Besides, we set another eligibility criteria that the household must have at least 1 food insecure event in the past 30 days, because we are interested in the causal effect of WIC on food security status among households that suffered from food insecurity.\n",
        "\n",
        "We include the following variables in our analysis:\n",
        "\n",
        "-   `HRFS30D4`: Food Security Rasch Scale Score in the past 30 days (100 - 1400). Higher score indicates lower food security.\n",
        "\n",
        "-   `HESP8`: WIC participation status (1: Yes, 2: No).\n",
        "\n",
        "-   `HRNUMHOU`: Number of people in the household.\n",
        "\n",
        "-   `HRHTYPE`: Household type.\n",
        "\n",
        "-   `GEREG`: Geographic region.\n",
        "\n",
        "-   `PRCHLD`: Presence of children in the household.\n",
        "\n",
        "-   `PRTAGE`: Age of the reference person.\n",
        "\n",
        "-   `PEEDUCA`: Education level.\n",
        "\n",
        "-   `PEMLR`: Employment status.\n",
        "\n",
        "-   `RACE`: recoded from `PTDTRACE` and `PEHSPNON`.\n",
        "\n",
        "-   `HEFAMINC`: Family income (take median of each class)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fss_20_data <- censusapi::getCensus(\n",
        "  name = \"cps/foodsec/dec\",\n",
        "  vintage = 2020,\n",
        "  vars = c(\"HRHHID\", \"HRHHID2\", \"HRNUMHOU\",\n",
        "           \"HRHTYPE\", \"GEREG\", \"HESP8\",\n",
        "           \"PRTAGE\", \"PEEDUCA\", \"PRCHLD\",\n",
        "           \"PEMLR\", \"PTDTRACE\", \"PEHSPNON\",\n",
        "           \"HEFAMINC\", \"HRFS30D1\", \"HHSUPWGT\",\n",
        "           \"PERRP\", \"HRFS30D4\")\n",
        "  ) |>\n",
        "  as_tibble() |>\n",
        "  filter(PERRP %in% c(40, 41),\n",
        "         HRFS30D1 %in% c(1, 2, 3),\n",
        "         PEMLR %in% c(1, 2, 3, 4, 5, 6, 7),\n",
        "         HESP8 %in% c(1, 2),\n",
        "         HRFS30D4 != -6) |>\n",
        "  mutate(HRFS30D1 = factor(HRFS30D1,\n",
        "                           levels = c(\"1\", \"2\", \"3\"),\n",
        "                           labels = c(\"Food Security\",\n",
        "                                      \"Low Food Security\",\n",
        "                                      \"Very Low Food Security\")),\n",
        "         HESP8 = ifelse(HESP8 == 1, 1, 0) |> \n",
        "           factor(levels = c(0, 1), labels = c(\"NoWIC\", \"WIC\")),\n",
        "         HRNUMHOU = as.numeric(HRNUMHOU),\n",
        "         HHSUPWGT = as.numeric(HHSUPWGT),\n",
        "         HRHTYPE = cut(as.numeric(HRHTYPE), breaks = c(0, 2, 5, 8, 10),\n",
        "                       labels = c(\"MarriedFamily\", \"UnmarriedFamily\",\n",
        "                                  \"Individual\", \"GroupQuarters\")) |> fct_drop(),\n",
        "         GEREG = factor(GEREG, levels = c(1, 2, 3, 4),\n",
        "                        labels = c(\"Northeast\", \"Midwest\", \"South\", \"West\")),\n",
        "         PEEDUCA = cut(as.numeric(PEEDUCA), breaks = c(30, 38, 42, 46),\n",
        "                       labels = c(\"LessThanHighSchool\",\n",
        "                                  \"HighSchoolOrAssociateDegree\",\n",
        "                                  \"CollegeOrHigher\")),\n",
        "         PEMLR = cut(as.numeric(PEMLR), breaks = c(0, 2, 4, 7),\n",
        "                     labels = c(\"Employed\", \"NotEmployed\",\n",
        "                                \"NotInLaborForce\")),\n",
        "         PRTAGE = as.numeric(PRTAGE),\n",
        "         PEHSPNON = factor(PEHSPNON, levels = c(2, 1),\n",
        "                           labels = c(\"Non-Hispanic\", \"Hispanic\")),\n",
        "         PTDTRACE = fct_recode(PTDTRACE,\n",
        "                          \"White\" = \"1\" ,\n",
        "                          \"Black\" = \"2\",\n",
        "                          \"AIAN\" = \"3\",\n",
        "                          \"Asian\" = \"4\",\n",
        "                          \"HPI\" = \"5\") |>\n",
        "           fct_other(keep = c(\"White\", \"Black\", \"AIAN\", \"Asian\", \"HPI\")),\n",
        "         PRCHLD = ifelse(PRCHLD == 0, \"NoChildren\", \"Children\") |> \n",
        "           as_factor() |> relevel(ref = \"NoChildren\"),\n",
        "         HEFAMINC = case_when(HEFAMINC == 1 ~ 2500,\n",
        "                              HEFAMINC == 2 ~ 6250,\n",
        "                              HEFAMINC == 3 ~ 8750,\n",
        "                              HEFAMINC == 4 ~ 11250,\n",
        "                              HEFAMINC == 5 ~ 13750,\n",
        "                              HEFAMINC == 6 ~ 17500,\n",
        "                              HEFAMINC == 7 ~ 22500,\n",
        "                              HEFAMINC == 8 ~ 27500,\n",
        "                              HEFAMINC == 9 ~ 32500,\n",
        "                              HEFAMINC == 10 ~ 37500,\n",
        "                              HEFAMINC == 11 ~ 45000,\n",
        "                              HEFAMINC == 12 ~ 55000,\n",
        "                              HEFAMINC == 13 ~ 67500,\n",
        "                              HEFAMINC == 14 ~ 87500,\n",
        "                              HEFAMINC == 15 ~ 125000,\n",
        "                              HEFAMINC == 16 ~ 175000),\n",
        "         HEFAMINC = as.numeric(HEFAMINC),\n",
        "         HRFS30D4 = as.numeric(HRFS30D4),\n",
        "  ) |>\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fss_20_data |>\n",
        "  select(HRFS30D4, HESP8, HRNUMHOU, HRHTYPE, GEREG, PRTAGE,\n",
        "         PEEDUCA, PRCHLD, PEMLR, HEFAMINC, PEHSPNON) |>\n",
        "  tbl_summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Two-sample t-test (simple linear regression)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "lm(HRFS30D4 ~ factor(HESP8), data = fss_20_data) |>\n",
        "  tbl_regression() |>\n",
        "  bold_labels() |>\n",
        "  bold_p(t = 0.05)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Multiple linear regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fit <- lm(HRFS30D4 ~ factor(HESP8) + HRNUMHOU + HRHTYPE + GEREG + PRTAGE +\n",
        "            PEEDUCA + PRCHLD + PEMLR + HEFAMINC + PEHSPNON, data = fss_20_data)\n",
        "fit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fit |>\n",
        "  tbl_regression() |>\n",
        "  bold_labels() |>\n",
        "  bold_p(t = 0.05)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### DoubleML workflow\n",
        "\n",
        "The Python and R package [DoubleML](https://docs.doubleml.org/) provide an implementation of the double / debiased machine learning framework of [Chernozhukov et al. (2018)](https://academic.oup.com/ectj/article/21/1/C1/5056401). The R package is built on top of mlr3 and the mlr3 ecosystem (Lang et al., 2019).\n",
        "\n",
        "::: {style=\"text-align: center;\"}\n",
        "<img src=\"https://docs.doubleml.org/stable/logo.png\" alt=\"DMLlogo\" width=\"300\"/>\n",
        ":::\n",
        "\n",
        "-   Data-backend\n",
        "\n",
        "    we initialize the data-backend and thereby declare the role of the outcome, the treatment, and the confounding variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "doubleML_data <- fss_20_data |>\n",
        "  mutate(HESP8 = ifelse(HESP8 == \"WIC\", 1, 0)) |>\n",
        "  data.table()\n",
        "\n",
        "obj_dml_data <- DoubleMLData$new(\n",
        "  doubleML_data,\n",
        "  y_col = \"HRFS30D4\",\n",
        "  d_cols = \"HESP8\",\n",
        "  x_cols = c(\"HRNUMHOU\", \"HRHTYPE\", \"GEREG\", \"PRCHLD\", \"PRTAGE\",\n",
        "             \"PEEDUCA\", \"PEMLR\", \"HEFAMINC\", \"PEHSPNON\")\n",
        ")\n",
        "\n",
        "obj_dml_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   Choose causal model\n",
        "\n",
        "    There are several models currently implemented in DoubleML which differ in terms of the underlying causal structure. In this example, we use the interactive regression model (IRM).\n",
        "\n",
        "::: {style=\"text-align: center;\"}\n",
        "<img src=\"causal.jpg\" alt=\"causalmodel\" width=\"700\"/>\n",
        ":::\n",
        "\n",
        "-   ML Methods\n",
        "\n",
        "    we can specify the machine learning tools used for estimation of the nuisance parts. We can generally choose any learner from mlr3 ecosystem in R. In this example, we use random forest for both the main equation and the confounding equation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "set.seed(2024)\n",
        "\n",
        "learner_g <- lrn(\"regr.ranger\", num.trees = 500, min.node.size = 2,\n",
        "                 max.depth = 5)\n",
        "learner_classif_m <- lrn(\"classif.ranger\", num.trees = 500,\n",
        "                         min.node.size = 2, max.depth = 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   DML specifications\n",
        "\n",
        "    we initialize and parametrize the model object which will later be used to perform the estimation. we specify the resampling, the dml algorithm and the score function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "set.seed(2024)\n",
        "\n",
        "doubleml_mod <- DoubleMLIRM$new(\n",
        "  obj_dml_data,\n",
        "  ml_g = learner_g, ml_m = learner_classif_m,\n",
        "  score = \"ATE\", dml_procedure = \"dml2\",\n",
        "  n_folds = 5, n_rep = 1\n",
        ")\n",
        "\n",
        "doubleml_mod"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   Estimation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "doubleml_mod$fit()\n",
        "doubleml_mod$summary()\n",
        "doubleml_mod$confint()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feedback\n",
        "\n",
        "```{=html}\n",
        "<iframe src=\"https://app.sli.do/event/aGHTYktNjhMJFDCe92w9Rt/embed/polls/5187fffc-a7a4-49aa-bb47-486a580d09ef\" width=\"75%\" height=\"400\" data-external=\"1\"></iframe>\n",
        "```\n",
        "[Slido](https://app.sli.do/event/aGHTYktNjhMJFDCe92w9Rt/embed/polls/5187fffc-a7a4-49aa-bb47-486a580d09ef)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "ir43",
      "language": "R",
      "display_name": "R 4.3.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}