---
title: "Data Science and R"
author: "Dr. Roch Nianogo, Bowen Zhang, Dr. Hua Zhou"
format:
  html:
    theme: cosmo
    embed-resources: true
    number-sections: true
    toc: true
    toc-depth: 4
    toc-location: left
    code-fold: false
    link-external-icon: true
    link-external-newwindow: true
knitr:
  opts_chunk: 
    cache: false    
    echo: true
    fig.align: 'center'
    # fig.width: 6
    # fig.height: 4
    message: FALSE
jupyter:
    kernelspec:
        name: "ir43"
        language: "R"
        display_name: "R 4.3.2"    
comments:
  hypothesis: true    
---

```{r}
#| code-fold: true
#| output: false

# setup code: install packages
library(tidyverse)
```

## Tell me about you

```{=html}
<iframe src="https://app.sli.do/event/aGHTYktNjhMJFDCe92w9Rt/embed/polls/81de78f7-a83c-4c28-9875-b82bbe7132d6" width="75%" height="500" data-external="1"></iframe>
```
[Slido](https://app.sli.do/event/aGHTYktNjhMJFDCe92w9Rt/embed/polls/81de78f7-a83c-4c28-9875-b82bbe7132d6)

## Roadmap

A typical data science project:

<p align="center">

<img src="./data-science.png" width="80%"/>

</p>

### Learning objectives

In the next 1.5 days, we learn

-   the life cycle of a data science project

-   some R ecosystems (tidyverse, tidymodels, dml) for Open Data Science

-   basic machine learning

-   policy evaluation using double machine learning

Dr. Roch Nianogo will lead the second part, from June 25 afternoon to June 26, with in-depth discussions of simulation modeling, causal inference, and linking data science and systems science.

### Course materials

All course materials are available on [GitHub](https://github.com/NIH-R25-ModelersAndStoryTellers/2024). During the course, you can

-   read the static [tutorial pages](https://github.com/NIH-R25-ModelersAndStoryTellers/2024), make comments, and ask questions; or

-   interactively run `qmd` files in RStudio on [Posit Cloud](https://posit.cloud/spaces/522857/join?access_code=jp20j2u42A7Ygue-OICZ2U4S6IWZCnI5GFp0r_N9) (sign up for a free account); or

-   interactively run `ipynb` files in Jupyter Notebook on [Binder](https://mybinder.org/v2/gh/NIH-R25-ModelersAndStoryTellers/binder-sandbox.git/main?urlpath=git-pull?repo=https://github.com/NIH-R25-ModelersAndStoryTellers/2024.git) (can be slow)

Adventurous ones can reproduce, improve, and generalize all the examples **on your own computer** by the following steps:

-   install [R](https://cran.r-project.org/), [RStudio](https://www.rstudio.com/products/rstudio/download/), and [Quarto](https://quarto.org/docs/get-started/)

-   git clone the [course repository](https://github.com/NIH-R25-ModelersAndStoryTellers/2024)

-   revise and render the qmd files

### Questions please

Please feel free to ask questions and make comments. You can

-   use the "raise hand" feature (âœ‹) in Zoom

-   type your questions in the Zoom chat (ðŸ’¬)

-   make comments or ask questions on tutorial pages (need to sign up an account on [hypothes.is](https://web.hypothes.is/))

## Data source

```{=html}
<iframe src="https://app.sli.do/event/aGHTYktNjhMJFDCe92w9Rt/embed/polls/6cf7fb80-becd-4f4b-82d3-5ff3a4dcaf74" width="75%" height="400" data-external="1"></iframe>
```
[Slido](https://app.sli.do/event/aGHTYktNjhMJFDCe92w9Rt/embed/polls/6cf7fb80-becd-4f4b-82d3-5ff3a4dcaf74)

![Census Bureau](https://www.census.gov/etc.clientlibs/census/clientlibs/census-pattern-library/resources/images/USCENSUS_IDENTITY_SOLO_BLACK_1.5in_R_no_padding.svg){fig-align="center" width="240"}

### Census and ACS

US Constitution Article I, Sections 2 and 9:

> The actual enumeration shall be made within three years after the first meeting of the Congress of the United States, and within every subsequent term of ten years, in such manner as they shall by law direct.

-   **Decennial census data**. Every 10 years (1790, 1800, ..., 2010, 2020) administered by the [United States Census Bureau](https://www.census.gov/en.html). Complete enumeration of the US population to assist with *apportionment*. A limited set of questions on race, ethnicity, age, sex, and housing tenure.

-   **American Community Survey (ACS)**. Before the 2010 decennial Census, 1 in 6 Americans also received the Census long form, which asked a wider range of demographic questions on income, education, language, housing, and more. The Census long form has since been replaced by the American Community Survey, which is now the premier source of detailed demographic information about the US population. The ACS is mailed to approximately 3.5 million households per year (around 3% of the US population), allowing for annual data updates. The Census Bureau releases two ACS datasets to the public:

    -   **1-year ACS**: covers areas of population 65,000 and greater

    -   **5-year ACS**: moving average of data over a 5-year period that covers geographies down to the Census block group.

### Current population survey (CPS)

The [Current Population Survey (CPS)](https://www.census.gov/programs-surveys/cps.html), sponsored jointly by the U.S. Census Bureau and the U.S. Bureau of Labor Statistics (BLS), is the primary source of labor force statistics for the population of the United States.

The CPS is one of the oldest, largest, and most well-recognized surveys in the United States. It is immensely important, providing information on many of the things that define us as individuals and as a society â€“ our work, our earnings, and our education.

In addition to being the primary source of monthly labor force statistics, the CPS is used to collect data for a variety of other studies that keep the nation informed of the economic and social well-being of its people. This is done by adding a set of supplemental questions to the monthly basic CPS questions. Supplemental inquiries vary month to month and cover a wide variety of topics such as child support, volunteerism, health insurance coverage, school enrollment, and **food security**. A listing and brief description of the CPS supplements are available [here](https://www.census.gov/programs-surveys/cps/about/supplemental-surveys.html).

### Food security supplement (CPS-FSS)

Take the **CPS Food Security Supplement December 2021 Public-Use Microdata File** as an example. The Food Security Supplement was completed for 30,343 interviewed households with 71,571 person records.

The microdata file includes data in four general categories:

-   Monthly labor force survey data (geographic, demographic, income, employment)
-   Food Security Supplement data (household food expenditures, use of food assistance programs, experiences and behaviors related to food security)
-   Food security status
-   Weighting variables

Food Security Supplement Questionnaire includes the following major sections:

-   Food Spending
-   Minimum Food Spending Needed
-   Food Assistance Program Participation
-   Food Sufficiency and Food Security
-   Ways of Avoiding or Ameliorating Food Deprivation

It is worth noting that beginning in 2015 and continuing through 2021, there were changes from previous years in how the Census Bureau processes some variables. Details can be found in the technical documentation, which can be found [here](https://www.census.gov/data/datasets/time-series/demo/cps/cps-supp_cps-repwgt/cps-food-security.html)

### Other data sources

-   [NIH All of US](https://commonfund.nih.gov/nutritionforprecisionhealth).

-   WIC administrative data.

## Introduction to R

```{=html}
<iframe src="https://app.sli.do/event/aGHTYktNjhMJFDCe92w9Rt/embed/polls/d9f4ab22-4a83-4ef9-ba60-62cd4c7ff915" width="75%" height="400" data-external="1"></iframe>
```
[Slido](https://app.sli.do/event/aGHTYktNjhMJFDCe92w9Rt/embed/polls/d9f4ab22-4a83-4ef9-ba60-62cd4c7ff915)

### Tidyverse

-   [tidyverse](https://www.tidyverse.org/) is a collection of R packages for data ingestion, wrangling, and visualization.

::: {style="text-align: center;"}
<img src="https://hbctraining.github.io/Intro-to-R/img/tidyverse_website.png" alt="Tidyverse"/>
:::

The Tidyverse suite of packages create and use data structures, functions and operators to make working with data more intuitive. The two most basic changes are in the use of pipes and tibbles.

-   The lead developer Hadley Wickham won the 2019 *COPSS Presidentsâ€™ Award* (the Nobel Prize of Statistics)

> for influential work in statistical computing, visualization, graphics, and data analysis; for developing and implementing an impressively comprehensive computational infrastructure for data analysis through R software; for making statistical thinking and computing accessible to large audience; and for enhancing an appreciation for the important role of statistics among data scientists.

#### Pipes

Stringing together commands in R can be quite daunting. Also, trying to understand code that has many nested functions can be confusing.

To make R code more human readable, the Tidyverse tools use the pipe, `%>%`, which was acquired from the **magrittr** package and comes installed automatically with Tidyverse. The pipe allows the output of a previous command to be used as input to another command instead of using nested functions.

```{r}
# A single command
sqrt(83)
```

```{r}
# Base R method of running more than one command
round(sqrt(83), digit = 2)
```

```{r}
# Running more than one command with piping
sqrt(83) %>% round(digit = 2)
```

The pipe represents a much easier way of writing and deciphering R code, and we will be taking advantage of it for all future activities.

::: callout-tip
R 4.1.0 introduced a native pipe operator `|>`, which is mostly compatible with the pipe `%>%` offered by the tidyverse package magrittr. For some subtle differences, see this [post](https://www.tidyverse.org/blog/2023/04/base-vs-magrittr-pipe/) by Hadley Wickham.
:::

```{r}
# R base pipe
sqrt(83) |> round(digit = 2)
```

#### Tibbles

A core component of the tidyverse is the tibble. Tibbles are a modern rework of the standard data.frame, with some internal improvements to make code more reliable. They are data frames, but do not follow all of the same rules. For example, tibbles can have column names that are not normally allowed, such as numbers/symbols.

The main differences between tibbles and data.frames relate to printing and subsetting.

-   `iris` is a data frame available in base R

::: {style="text-align: center;"}
<img src="https://miro.medium.com/v2/resize:fit:1100/format:webp/1*ZK9_HrpP_lhSzTq9xVJUQw.png" alt="iris" width="500"/>
:::

```{r}
# By default, R displays ALL rows of a regular data frame!
iris
```

-   Convert a regular data frame to tibble, which by default only displays the first 10 rows of data.

```{r}
# Convert iris to a tibble
iris_tb <- as_tibble(iris)
iris_tb
```

```{r}
# If subsetting a single column from a data.frame, R will output a vector
iris[, "Sepal.Length"]
```

```{r}
# If subsetting a single column from a tibble, R will output a tibble
iris_tb[, "Sepal.Length"]
```

Also note that if you use piping to subset a tibble, then the notation is slightly different, requiring a placeholder `.` prior to the `[ ]` or `$`.

```{r}
#| eval: false

# Return a vector
iris_tb$Sepal.Length
iris_tb[["Sepal.Length"]]
iris_tb[[1]]

# Return a tibble
iris_tb[, "Sepal.Length"]
iris_tb[, 1]

# Use piping
iris_tb %>% .$Sepal.Length
iris_tb %>% .[, "Sepal.Length"]
```

#### dplyr

The most useful tool in the tidyverse is dplyr. Itâ€™s a Swiss-army knife for data wrangling. dplyr has many handy functions that we recommend incorporating into your analysis.

-   Operations on rows:
    -   `arrange()` changes the ordering of the rows.
    -   `filter()` picks cases based on their values.
    -   `distinct()` removes duplicate entries.
    -   `slice_*()` selects rows by position.
-   Operations on columns:
    -   `select()` extracts columns and returns a tibble.
    -   `mutate()` adds new variables that are functions of existing variables.
    -   `rename()` easily changes the name of a column(s).
    -   `pull()` extracts a single column as a vector.
-   Grouped operations:
    -   `group_by()` aggregates data by one or more variables.
    -   `summarise()` reduces multiple values down to a single summary.
-   `_join()` functions that merge two data frames together, including `inner_join()`, `left_join()`, `right_join()`, and `full_join()`.

The [Posit dplyr cheat sheet](https://rstudio.github.io/cheatsheets/data-transformation.pdf) is extremely intuitive and helpful.

Some examples of using dplyr functions.

-   Filter observations with `Sepal.Length` greater than 5.0, arrange the data by `Sepal.Length` in descending order, and create a new column `Sepal.Length_2` that is the square of `Sepal.Length`.

```{r}
iris_tb |>
  filter(Sepal.Length > 5.0) |>
  arrange(desc(Sepal.Length)) |>
  mutate(Sepal.Length_2 = Sepal.Length^2) |>
  print()
```

-   Select columns `Species`, and find the distinct values of `Species`

```{r}
iris_tb |>
  select(Species) |>
  distinct()
```

-   Count the number of rows in each species

```{r}
iris_tb |>
  group_by(Species) |> 
  summarize(n = n())
```

```{r}
# Shortcut for group_by() |> summarize(n = n())
iris_tb |>
  count(Species)
```

-   Calculate the mean of `Sepal.Length` for each `Species`

```{r}
iris_tb |>
  group_by(Species) |>
  summarize(mean_Sepal_Length = mean(Sepal.Length))
```

-   Find the observation with the maximum `Sepal.Length` for each `Species`

```{r}
iris_tb |>
  group_by(Species) |>
  slice_max(Sepal.Length)
```

#### Combine variables (columns)

-   Demo tables

```{r}
(x <- tribble(
  ~key, ~val_x,
  1, "x1",
  2, "x2",
  3, "x3"
))
```

```{r}
(y <- tribble(
  ~key, ~val_y,
  1, "y1",
  2, "y2",
  4, "y3"
))
```

-   An **inner join** matches pairs of observations whenever their keys are equal:

<p align="center">

<img src="./join-inner.png" height="150"/>

</p>

```{r}
inner_join(x, y, by = "key")
```

-   An **outer join** keeps observations that appear in at least one of the tables.

-   Three types of outer joins: **left join**, **right join**, and **full join**.

<p align="center">

<img src="./join-outer.png" width="50%"/>

</p>

-   A **left join** keeps all observations in `x`.

```{r}
left_join(x, y, by = "key")
```

-   A **right join** keeps all observations in `y`.

```{r}
right_join(x, y, by = "key")
```

-   A **full join** keeps all observations in `x` and `y`.

```{r}
full_join(x, y, by = "key")
```

-   One table has duplicate keys.

<p align="center">

<img src="./join-one-to-many.png" height="200"/>

</p>

```{r}
x <- tribble(
  ~key, ~val_x,
  1, "x1",
  2, "x2",
  2, "x3",
  1, "x4"
)
y <- tribble(
  ~key, ~val_y,
  1, "y1",
  2, "y2"
)
left_join(x, y, by = "key")
```

-   Both tables have duplicate keys. You get all possible combinations, the Cartesian product:

<p align="center">

<img src="./join-many-to-many.png" height="250"/>

</p>

```{r}
x <- tribble(
  ~key, ~val_x,
  1, "x1",
  2, "x2",
  2, "x3",
  3, "x4"
)
y <- tribble(
  ~key, ~val_y,
  1, "y1",
  2, "y2",
  2, "y3",
  3, "y4"
)

left_join(x, y, by = "key")
```

#### Combine cases (rows)

-   `semi_join(x, y)` keeps the rows in `x` that have a match in `y`.

<p align="center">

<img src="./join-semi.png" height="200"/>

</p>

```{r}
x <- tribble(
  ~key, ~val_x,
  1, "x1",
  2, "x2",
  3, "x3"
)

y <- tribble(
  ~key, ~val_y,
  1, "y1",
  2, "y2",
  4, "y3"
)

semi_join(x, y, by = "key")
```

-   `anti_join(x, y)` keeps the rows that donâ€™t have a match.

<p align="center">

<img src="./join-anti.png" height="200"/>

</p>

```{r}
anti_join(x, y, by = "key")
```

### Data visualization using ggplot

-   `ggplot2` is a powerful and flexible package for creating plots in R.

-   The basic idea is to map data to aesthetics (color, shape, size, etc.) and then add layers (points, lines, bars, etc.) to the plot.

```{r}
ggplot(iris_tb) +
  # Scatter plot
  geom_point(mapping = aes(
    x = Petal.Length, 
    y = Petal.Width, 
    color = Species
    )) + 
  # Add one more layer of line plot
  geom_smooth(mapping = aes(
    x = Petal.Length, 
    y = Petal.Width, 
    color = Species
    )) +
  # Axis labels, title, caption, etc
  labs(x = "Petal Length (cm)",
       y = "Petal Width (cm)",
  )
```

-   Again the [Posit ggplot2 cheat sheet](https://rstudio.github.io/cheatsheets/data-visualization.pdf) is extremely intuitive and helpful.

-   Interactive plots are easily achieved by `plotly` package.

-   Interactive apps can be developed by the popular `shiny` package.

### Exercises

1.  Find the median `Petal.Length` of each Iris species.

    ```{r}
    # try to use pipe

    ```

2.  Plot the histograms of `Petal.Length`, grouped by `Species`.

    ```{r}
    # geom_histogram

    ```

## Feedback

```{=html}
<iframe src="https://app.sli.do/event/aGHTYktNjhMJFDCe92w9Rt/embed/polls/60aa4347-c88f-4ca2-92ca-8d1b3da48dbe" width="75%" height="400" data-external="1"></iframe>
```
[Slido](https://app.sli.do/event/aGHTYktNjhMJFDCe92w9Rt/embed/polls/60aa4347-c88f-4ca2-92ca-8d1b3da48dbe)
